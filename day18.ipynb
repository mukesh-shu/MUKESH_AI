{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mukesh kumar\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from speechrecognition) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2023.7.22)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: comtypes in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (1.2.0)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\mukesh kumar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\mukesh kumar\\appdata\\roaming\\python\\python310\\site-packages (from pyttsx3) (306)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install nltk\n",
    "!python -m pip install speechrecognition\n",
    "!python -m pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import nltk\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "hog = cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "vid = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ack, img = vid.read()\n",
    "    if ack:\n",
    "        people, weights = hog.detectMultiScale(\n",
    "            cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "            winStride=(15,15)\n",
    "        )\n",
    "        for x,y,w,h in people:\n",
    "            cv2.rectangle(\n",
    "                img, pt1=(x,y), pt2=(x+w,y+w),color=(0,0,255), thickness=5,\n",
    "            )\n",
    "        sleep(0.1)\n",
    "        cv2.imshow('preview', img)\n",
    "        if cv2.waitKey(delay=1) == ord('q'):\n",
    "                        break\n",
    "cv2.destroyAllWindows();cv2.waitKey(1)\n",
    "vid.release()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule based chat-bot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3 # chat to voice coversion \n",
    "tts = pyttsx3.init()\n",
    "tts.setProperty('rate', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts.say('hello iam speaking for you from your computer')\n",
    "tts.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import webbrowser as web\n",
    "rec = sr.Recognizer()\n",
    "flag = False\n",
    "while True:\n",
    "  with sr.Microphone() as mic:\n",
    "    print('Speak:')\n",
    "    audio = rec.listen(mic,phrase_time_limit=3,timeout=5)\n",
    "    try:\n",
    "        text = rec.recognize_google(audio).lower()\n",
    "        if flag == True:\n",
    "            if 'search' in text:\n",
    "                item = text.split('search')[-1].strip()\n",
    "                flipkart_url = 'https://flipkart.com/search?q='\n",
    "                amazon_url = 'https://amazon.in/s?k='\n",
    "                web.open_new(flipkart_url + item)\n",
    "                web.open_new_tab(amazon_url + item)\n",
    "            flag = False\n",
    "        if 'ok google' in text:\n",
    "            flag = True\n",
    "        elif 'stop' in text:\n",
    "           break   \n",
    "        print('you said', text) # for text \n",
    "        #tts.say(text) # for speech\n",
    "        #tts.runAndWait()\n",
    "    except Exception as err:\n",
    "        print(err)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot\n",
    "from nltk.chat.util import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = r'(.*)your name(.*)'\n",
    "a1 = ['my name is chatbot','I Am a chatbot']\n",
    "q2 = r'kiya kuch ajj acha hoga'\n",
    "a2 = ['haan','mujhe kiya pata','mrein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1,a1],\n",
    "    [q2,a2]\n",
    "]\n",
    "cb = Chat(qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Am a chatbot\n"
     ]
    }
   ],
   "source": [
    "ques = input('enter ques').lower()\n",
    "resp = cb.respond(ques)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression\n",
    "####################\n",
    "#() capture and group\n",
    "#. Any character new line nhi honi chiye\n",
    "#* zero or more occurences\n",
    "#|  or\n",
    "#[]  set of charachters\n",
    "#a-z \n",
    "#[a-c]\n",
    "#[A-Z]\n",
    "#0-9\n",
    "# ^    starts with\n",
    "# $  ends with\n",
    "# ?      zero or more occurence\n",
    "# +   one or more occurence\n",
    "#  {}  exact number of occurence\n",
    "#\\w  only word charaters\n",
    "#\\ W not word characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chat.util import Chat\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "q1 = r'(.*)your name(.*)'\n",
    "a1 = ['my name is chatbot','I Am a chatbot']\n",
    "q2 = r'kiya kuch ajj acha hoga'\n",
    "a2 = ['haan','mujhe kiya pata','mrein kyo batau']\n",
    "qa_pair = [\n",
    "    [q1,a1],\n",
    "    [q2,a2]\n",
    "]\n",
    "cb = Chat(qa_pair)\n",
    "tts = pyttsx3.init()\n",
    "rec = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "  with sr.Microphone() as mic:\n",
    "    print('Speak:')\n",
    "    audio = rec.listen(mic,phrase_time_limit=3,timeout=5)\n",
    "    try:\n",
    "        text = rec.recognize_google(audio).lower()\n",
    "        if flag == True:\n",
    "            if 'search' in text:\n",
    "                item = text.split('search')[-1].strip()\n",
    "                flipkart_url = 'https://flipkart.com/search?q='\n",
    "                amazon_url = 'https://amazon.in/s?k='\n",
    "                web.open_new(flipkart_url + item)\n",
    "                web.open_new_tab(amazon_url + item)\n",
    "            else:\n",
    "               resp = cb.respond(text)\n",
    "               if resp == None:\n",
    "                  tts.say('sorry, I dont know')\n",
    "               else:\n",
    "                  tts.say(resp)\n",
    "               tts.runAndWait()\n",
    "            flag = False\n",
    "        if 'ok google' in text:\n",
    "            flag = True\n",
    "        elif 'stop' in text:\n",
    "           break   \n",
    "        print('you said', text) # for text \n",
    "        #tts.say(text) # for speech\n",
    "        #tts.runAndWait()\n",
    "    except Exception as err:\n",
    "        print(err)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
